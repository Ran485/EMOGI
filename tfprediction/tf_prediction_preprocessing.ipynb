{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Prediction of Transcription Factors using GCNs\n",
    "To evaluate the quality of graph convolutional networks on PPI networks and gene expression, I'll use the dual RNA-seq gene expression from humans. I want to predict if a gene is a transcription factor (TF) or not, using only that information and a limited number of genes as training set.\n",
    "\n",
    "**In this notebook, I want to prepare the data for use with the GCN.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py, os\n",
    "from sklearn.model_selection_selection import train_test_split\n",
    "import mygene\n",
    "\n",
    "from goatools.base import download_go_basic_obo, download_ncbi_associations\n",
    "from goatools.associations import read_ncbi_gene2go\n",
    "from goatools.go_search import GoSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# constants\n",
    "TEST_RATIO = 0.4\n",
    "VAL_SIZE = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 1. Load PPI network with Gene Expression\n",
    "We first need the PPI network and gene expression which was already processed by the preprocessing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fname = '../data/preprocessing/ppi_networks.h5'\n",
    "with h5py.File(fname, 'r') as f:\n",
    "    gene_expression_data = pd.DataFrame(f['gene_expression'][:])\n",
    "    ppi_network = f['consensusPathDB_ppi'][:]\n",
    "    gene_names = f['gene_names'][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2. Get Labels if a Gene is a TF or Not for all Genes\n",
    "I will do that using goatools which is a library and part of bioconda. This involves multiple steps. First, I have to get the IDs of genes that annotated to the TF GO term or one of it's children.\n",
    "Then, I have to convert the entrez IDs to Ensembl IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EXISTS: go-basic.obo\n",
      "  EXISTS: gene2go\n",
      "  READ: gene2go\n",
      "17529 GO terms associated with human NCBI Entrez GeneIDs\n",
      "load obo file go-basic.obo\n",
      "go-basic.obo: fmt(1.2) rel(2017-11-02) 47,030 GO Terms\n",
      "1248 human NCBI Entrez GeneIDs under Transcription Factors found.\n"
     ]
    }
   ],
   "source": [
    "# download GO terms and associations\n",
    "obo_fname = download_go_basic_obo()\n",
    "gene2go = download_ncbi_associations()\n",
    "# get all GO terms associated with human genes (maybe only the ones contained in gene_names?)\n",
    "go2geneids_human = read_ncbi_gene2go(\"gene2go\", taxids=[9606], go2geneids=True)\n",
    "print(\"{N} GO terms associated with human NCBI Entrez GeneIDs\".format(N=len(go2geneids_human)))\n",
    "\n",
    "# search in there for GO ID GO:0003700 (DNA binding TF activity)\n",
    "srchhelp = GoSearch(\"go-basic.obo\", go2items=go2geneids_human)\n",
    "# Details of search are written to a log file\n",
    "fout_allgos = \"TF_GO_search.log\" \n",
    "with open(fout_allgos, \"w\") as log:\n",
    "    # Add children GOs of TF\n",
    "    tf_with_children = srchhelp.add_children_gos(['GO:0003700', 'GO:0000130'])\n",
    "    # Get Entrez GeneIDs for cell cycle GOs\n",
    "    entrez_ids = list(srchhelp.get_items(tf_with_children))\n",
    "print(\"{N} human NCBI Entrez GeneIDs under Transcription Factors found.\".format(N=len(entrez_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "querying 1-1000...done.\n",
      "querying 1001-1248...done.\n",
      "Finished.\n",
      "1232 human transcription factors with corresponding Ensembl ID\n"
     ]
    }
   ],
   "source": [
    "# convert the entrez genes to ensembl IDs\n",
    "mg = mygene.MyGeneInfo()\n",
    "res = mg.querymany(entrez_ids, scopes='entrezgene', fields='ensembl.gene', species='human')\n",
    "f = lambda x: x['ensembl'][0]['gene'] if type(x['ensembl']) is list else x['ensembl']['gene']\n",
    "ens_ids = [f(x) for x in res if 'ensembl' in x]\n",
    "print (\"{} human transcription factors with corresponding Ensembl ID\".format(len(ens_ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 3. Split genes into training, testing and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split Training and Testing with 40.0% test nodes\n",
      "Training Nodes: 5274\t# of Labels in Train Set: 428\n",
      "Testing Nodes: 3850\t# of Labels in Test Set: 310\n"
     ]
    }
   ],
   "source": [
    "# Construct DF with label column and gene expression\n",
    "gene_names_df = pd.DataFrame(gene_names,\n",
    "                             index=gene_names[:, 0],\n",
    "                             columns=['ID', 'name']\n",
    "                            ).drop('ID', axis=1)\n",
    "gene_names_df['node_number'] = np.arange(0, gene_names_df.shape[0])\n",
    "ge = gene_expression_data.set_index(gene_names_df.index)\n",
    "features_labeled = ge.join(gene_names_df)\n",
    "assert (features_labeled.isnull().sum().sum() == 0)\n",
    "features_labeled['label'] = gene_names_df.index.isin(ens_ids)\n",
    "\n",
    "# split for training, testing & validation\n",
    "X_train, X_test = train_test_split(features_labeled,\n",
    "                                   stratify=features_labeled.label,\n",
    "                                   test_size=TEST_RATIO\n",
    "                                  )\n",
    "X_val = X_train[-VAL_SIZE:]\n",
    "X_train = X_train[:-VAL_SIZE]\n",
    "\n",
    "print (\"Split Training and Testing with {}% test nodes\".format(TEST_RATIO*100.))\n",
    "print (\"Training Nodes: {}\\t# of Labels in Train Set: {}\".format(X_train.shape[0], X_train.label.sum()))\n",
    "print (\"Testing Nodes: {}\\t# of Labels in Test Set: {}\".format(X_test.shape[0], X_test.label.sum()))\n",
    "\n",
    "# construct training, testing and validation masks\n",
    "def build_mask(features_labeled, X):\n",
    "    mask = features_labeled[features_labeled.isin(X)].label\n",
    "    mask[mask.isnull()] = 0\n",
    "    # sanity check\n",
    "    assert (np.all(mask.index == gene_names[:, 0]))\n",
    "    return mask.values\n",
    "\n",
    "train_mask = build_mask(features_labeled, X_train)\n",
    "test_mask = build_mask(features_labeled, X_test)\n",
    "val_mask = build_mask(features_labeled, X_val)\n",
    "\n",
    "# construct labels\n",
    "y_train = pd.get_dummies(features_labeled[features_labeled.isin(X_train)].label).values\n",
    "y_test = pd.get_dummies(features_labeled[features_labeled.isin(X_test)].label).values\n",
    "y_val = pd.get_dummies(features_labeled[features_labeled.isin(X_val)].label).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 4. Write PPI Network, Gene Expression & Label Information to HDF5 Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "string_dt = h5py.special_dtype(vlen=str)\n",
    "f = h5py.File('../data/tfprediction/gcn_input.h5', 'w')\n",
    "\n",
    "# add network & features\n",
    "f.create_dataset('network', data=ppi_network, shape=ppi_network.shape)\n",
    "f.create_dataset('features', data=gene_expression_data, shape=gene_expression_data.shape)\n",
    "f.create_dataset('gene_names', data=gene_names, dtype=string_dt)\n",
    "\n",
    "# add labels\n",
    "f.create_dataset('y_train', data=y_train, shape=y_train.shape)\n",
    "f.create_dataset('y_test', data=y_test, shape=y_test.shape)\n",
    "f.create_dataset('y_val', data=y_val, shape=y_val.shape)\n",
    "\n",
    "# add masks\n",
    "f.create_dataset('mask_train', data=train_mask, shape=train_mask.shape)\n",
    "f.create_dataset('mask_test', data=test_mask, shape=test_mask.shape)\n",
    "f.create_dataset('mask_val', data=val_mask, shape=val_mask.shape)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
